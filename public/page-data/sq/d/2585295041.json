{"data":{"featured":{"edges":[{"node":{"frontmatter":{"title":"Object Detection and Localization in Compressive Sensing Video","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEAf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAGdtizBwn//xAAaEAEAAgMBAAAAAAAAAAAAAAABAAIQESEi/9oACAEBAAEFAmup6lUS3cE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGxAAAQQDAAAAAAAAAAAAAAAAAQAQETIhMZH/2gAIAQEABj8CFuNYrMrZb//EABsQAQADAAMBAAAAAAAAAAAAAAEAESFBYXGB/9oACAEBAAE/IbCMBaxp5plpfsQYEjtluGHsAXP/2gAMAwEAAgADAAAAEKDf/8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQMBAT8QR//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EAB4QAQEAAgEFAQAAAAAAAAAAAAERACExQWFxkaHB/9oACAEBAAE/ENMBlRG8eO+InYZuhX0aw4B02vGQKp2Kn1y4iJCXIcZEBC/hn//Z"},"images":{"fallback":{"src":"/static/2407df0d0156fe333a242e66647488bd/2b365/cs.jpg","srcSet":"/static/2407df0d0156fe333a242e66647488bd/1849b/cs.jpg 175w,\n/static/2407df0d0156fe333a242e66647488bd/3f5de/cs.jpg 350w,\n/static/2407df0d0156fe333a242e66647488bd/2b365/cs.jpg 700w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/2407df0d0156fe333a242e66647488bd/dae43/cs.avif 175w,\n/static/2407df0d0156fe333a242e66647488bd/d7667/cs.avif 350w,\n/static/2407df0d0156fe333a242e66647488bd/7ec1a/cs.avif 700w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/2407df0d0156fe333a242e66647488bd/5d873/cs.webp 175w,\n/static/2407df0d0156fe333a242e66647488bd/26a00/cs.webp 350w,\n/static/2407df0d0156fe333a242e66647488bd/f23f0/cs.webp 700w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":394}}},"tech":["Deep Learning","Computer Vision","Object Detection and Localization","Compressive Sensing","NVIDIA Jetson TX2"],"github":"https://gitlab.com/neuronics/object_detection_compressed_frames","external":"https://arxiv.org/abs/1912.08519","conference":"ICIP 2021"},"html":"<p><a>A REAL-TIME OBJECT DETECTION AND LOCALIZATION IN COMPRESSIVE SENSED VIDEO</a>\n<i>*ICIP 2021 Paper Link yet to be linked</i></p>\n<ul>\n<li>Object detection and localization can be possible directly in the Compressed Domain (easily upto 20x compression).</li>\n<li>Achieved <a>SOTA 46.27% mAP</a>(Mean Average Precision) on a GeForce GTX 1080 Ti with an inference time of 23ms.</li>\n<li>Deployed on a NVIDIA TX2 embedded board with <a>45.11% mAP</a> with an inference time of <a>34ms</a>.</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Proto-Object Based Visual Saliency","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAABJ0AAASdAHeZh94AAAD40lEQVQ4y3VT7WtbZRR/pAj74AfZwP/BoZ9kuIE4+0GqdC1rh6AyNtDJvqjUlgmCYLvpdusaXMWpMFcWhrG0Xbu2qcmWNFnShLAlNmltSXKT3Lze3Ny33Jfcm+S++6RvlIGHw305z/md3znPOQfc/+PX2z+O3vnpB9v1Mce9u41mu4ITFM3QDEtSDF6tyc2Woummptm35C+fScPB1tCcNDzBErUWCFzvj149EZ/odl95w4d8RFBsvV6nKDqdThMEwfO8oiim1ZGzX2Ogh+k6o4Fu/YWXKyjKA3npc8t9Xnd/Zjo/ttxXOLGJ41VBbPCCRNMsLwiyLEtS07LaH34QBSBw9HT1yCvYS0cCWJ4FuP2iaO9pOc4Kt08xU+cbTS2ZTGYyaKlUDodDKJrWO9LhHhhAAUh3dYUB2O56MZzJciA1/W3VcbnpHKH+/KQ8801LNTY3N7xer9/nCwYCKIpqmmbu5I3cLL773mZ/f6i3NzY4GMCrIoBWjhfz+VIuX2xIEvz95efJcwODI8Mj10bHok+fQothGPApCAzDlFgWJ8k8x9WabQWCTdOEp7rRSU+DTjcRpK/3zKVPL10dHfOveg/AkB++ocIPWEhb0YB1SCC6Ax5HXj/+6skTb0Kdn50+AB8WSPg8eNdp8tZk9zvdfb39b791em7GAS2ttqKoGlRNM3ZVUXW5pYK9ODu5W4apGyYviHA2CJIiaqTQkAxzn80wVVVXtY52AukGsP5fzJ1bFnl2eXF2fHLicdD/nAOAhbbL5Xomw6GonE6pHF8laCxbyGQKpXJNEuX4VnZhaWVt6g6xFuhEPAw2q1Upl9sOhdd9/kosxuTKBYKJPItHovFMEd/CpT7Ee+3+On38NfzYMRPSyLLAcfvMlTJRrThmHeM2xO/zcAUcRZNTd3+7ZbsRT6znGPXy78Hv7wUrPe+XTp5KeB7ZHfblhw9UVd0DczSVzeWisVgplyXRAkmRaRSN/RPLlvCmamxlS7kKmUrlQpEYxXKReBLu2W7bgV4swhaRJIXl81q7RaQwaMVxnKwRvKxwkoIVinSd9zwJujyrKTQ7v+ikGHb3OoFRKloa7KHaVlR4eWSmAA86fVUVWTWqrPjwb+/CyuMHyy7H7II3GFlZDdUYfg9s1WrhYPCLoaGhr4Y3EnEGq9hstosXLoyNfkfQXJnkpued8073zILzr7nFJRcM5KE5cQ9sViob4bDL6Qz6n2gcl49vrwbWXO5HcDHFtsHDouHmCPK/aWw7U2T5BkxH258bYKmqSZJWvW4xjFEsKnKzs/hwNjSDaSj6zsBuJBLjyA0EQfIYdjA8UP4DXrPh1niLydEAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/99817a17252c97073620f0bec595ba2a/c48cd/proto-motion.png","srcSet":"/static/99817a17252c97073620f0bec595ba2a/e6966/proto-motion.png 175w,\n/static/99817a17252c97073620f0bec595ba2a/c6fbd/proto-motion.png 350w,\n/static/99817a17252c97073620f0bec595ba2a/c48cd/proto-motion.png 700w,\n/static/99817a17252c97073620f0bec595ba2a/891f1/proto-motion.png 1400w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/99817a17252c97073620f0bec595ba2a/9e5c5/proto-motion.avif 175w,\n/static/99817a17252c97073620f0bec595ba2a/efec3/proto-motion.avif 350w,\n/static/99817a17252c97073620f0bec595ba2a/39372/proto-motion.avif 700w,\n/static/99817a17252c97073620f0bec595ba2a/411d0/proto-motion.avif 1400w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/99817a17252c97073620f0bec595ba2a/c54d4/proto-motion.webp 175w,\n/static/99817a17252c97073620f0bec595ba2a/fbcf8/proto-motion.webp 350w,\n/static/99817a17252c97073620f0bec595ba2a/c85d5/proto-motion.webp 700w,\n/static/99817a17252c97073620f0bec595ba2a/829b2/proto-motion.webp 1400w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":706}}},"tech":["Computer Vision","Visual Saliency","CUDA","Neuromorphic Proto-Object","NVIDIA Jetson TX"],"github":"https://gitlab.com/neuronics/visual_saliency","external":"https://ieeexplore.ieee.org/abstract/document/8702200","conference":"ISCAS 2019"},"html":"<p><a>Real-Time Implementation of Proto-Object Based Visual Saliency</a></p>\n<ul>\n<li>We demonstrate a real-time implementation of a proto sobject based neuromorphic visual saliency model</li>\n</ul>"}},{"node":{"frontmatter":{"title":"n-HAR","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAABJ0AAASdAHeZh94AAACgUlEQVQoz11TW0/iYBDlFxuNSHzwxQck+mDwLnglIRpd4g3RBRHjsioIK7DSVrYGql1q6QddoBdacHHPWt0sTqA5Mx9nzpnph+3lPbrdrq7rv18DABXTNJ+fnwEURUERqaqqL/+FDV8c4ElR1MLCQigUOjk5AYjH4xsbG2tra8lkcm5u7ujoCPX5+XmWZS2lN7KFgsHgwMDA1NSU1+sF8Pv9LpfLbrdvbW319/cvLi4uLy/39fUlEol/ejbLAOylUqmDg4PLy8vr6+v9/f1cLgdxGIEj1MFBfXd3l+f5HmWr09nZGewFAgFYmJmZicVim5ublv/Z2dm9vb3j42PUGYb5qIxA16GhIRx7PB6A7e3tyclJh8Oxs7MzPDyM4urqKsaB/kcykmw2i944u7m5wXpomsYIWFKhUIhEIul0Gj9AXRCEj7aR4GB8fNzn80HT6XQixeYmJibARB0jwBoAdtGjbKFoNAq3eBkrKyvwGQh8mp6eHhkZAQfp0pJ3fX19cHAQe+0hQxbbliQpn8+XStzjIw+rQlkolUoA5XKZphmOe0BgFiJJlue/ZCC0AbnT6egthIGPaZiaquHZMgxdb7XbbcNAvYVLBmBduzdlaF5dXYmiqDYbbaPVaNQ1XVE1pak0TFMri4S9f6jViCA8cRxXJQT8N7KmaYeHh2NjztPTGC81WELS1BNbrH1nqllazOQl5p7k0z9/1eRwOAxasVhEi0wmg/tvu729HR0ddbvdVJ7ipfo9qX7+Qt2VyDeai35lC48ky4hMTryIXxR+FKBmkbFd/FtshJDz83PsBnPXZRnDqY0qPGtaXWnKLVPn+QeGucPY5mtgf5VKRZZl7OgPkgrsB8wcVF8AAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/f48068e565cf5d616dbf543a415d462b/3bd79/n-har.png","srcSet":"/static/f48068e565cf5d616dbf543a415d462b/fe11f/n-har.png 175w,\n/static/f48068e565cf5d616dbf543a415d462b/8caa9/n-har.png 350w,\n/static/f48068e565cf5d616dbf543a415d462b/3bd79/n-har.png 700w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/f48068e565cf5d616dbf543a415d462b/0b4ad/n-har.avif 175w,\n/static/f48068e565cf5d616dbf543a415d462b/bee7b/n-har.avif 350w,\n/static/f48068e565cf5d616dbf543a415d462b/19e93/n-har.avif 700w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/f48068e565cf5d616dbf543a415d462b/e35d6/n-har.webp 175w,\n/static/f48068e565cf5d616dbf543a415d462b/f0765/n-har.webp 350w,\n/static/f48068e565cf5d616dbf543a415d462b/ef7dc/n-har.webp 700w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":531}}},"tech":["Event Based Neurmorphic Vision","Computer Vision","Deep Learning","Human Activity Recognition"],"github":"https://gitlab.com/neuronics/n-har","external":"https://ieeexplore.ieee.org/document/8702581","conference":"ISCAS 2019"},"html":"<p><a>N-HAR: A Neuromorphic Event-Based Human Activity Recognition System using Memory Surfaces. </a></p>\n<p>A system to achieve the task of human activity recognition based on the event-based camera data. We achieved a <a>SOTA accuracy of 94.3%</a> using event memory surfaces on our activity recognition dataset.</p>"}}]}}}